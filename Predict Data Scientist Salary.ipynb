{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.sparse import hstack, csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Final_Train_Dataset.csv')\n",
    "test = pd.read_csv('Final_Test_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experience</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_desig</th>\n",
       "      <th>job_type</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>company_name_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5-7 yrs</td>\n",
       "      <td>Exp: Minimum 5 years;Good understanding of IOC...</td>\n",
       "      <td>Senior Exploit and Vulnerability Researcher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>team skills, communication skills, analytical ...</td>\n",
       "      <td>Delhi NCR(Vikas Puri)</td>\n",
       "      <td>6to10</td>\n",
       "      <td>3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10-17 yrs</td>\n",
       "      <td>He should have handled a team of atleast 5-6 d...</td>\n",
       "      <td>Head SCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ppc, logistics, inventory management, supply c...</td>\n",
       "      <td>Sonepat</td>\n",
       "      <td>10to15</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 experience                                    job_description  \\\n",
       "0           0    5-7 yrs  Exp: Minimum 5 years;Good understanding of IOC...   \n",
       "1           1  10-17 yrs  He should have handled a team of atleast 5-6 d...   \n",
       "\n",
       "                                     job_desig job_type  \\\n",
       "0  Senior Exploit and Vulnerability Researcher      NaN   \n",
       "1                                     Head SCM      NaN   \n",
       "\n",
       "                                          key_skills               location  \\\n",
       "0  team skills, communication skills, analytical ...  Delhi NCR(Vikas Puri)   \n",
       "1  ppc, logistics, inventory management, supply c...                Sonepat   \n",
       "\n",
       "   salary  company_name_encoded  \n",
       "0   6to10                  3687  \n",
       "1  10to15                   458  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)\n",
    "#test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19802 entries, 0 to 19801\n",
      "Data columns (total 9 columns):\n",
      "Unnamed: 0              19802 non-null int64\n",
      "experience              19802 non-null object\n",
      "job_description         15384 non-null object\n",
      "job_desig               19802 non-null object\n",
      "job_type                4797 non-null object\n",
      "key_skills              19801 non-null object\n",
      "location                19802 non-null object\n",
      "salary                  19802 non-null object\n",
      "company_name_encoded    19802 non-null int64\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "#test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=['key_skills'])\n",
    "\n",
    "df_train = train[['key_skills', 'job_desig', 'job_description', 'location', 'job_type', 'experience','salary']]\n",
    "df_test = test[['key_skills', 'job_desig', 'job_description', 'job_type', 'experience', 'location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_skills(skl):\n",
    "    skills = str(skl).lower()\n",
    "    skills = re.sub(r'\\...','', skills)\n",
    "    skills = re.sub(r',','', skills)\n",
    "    skills = re.sub(r'\\s+', ' ', skills)\n",
    "    return skills\n",
    "\n",
    "df_train['skills_cleaned'] = df_train['key_skills'].apply(clean_skills)\n",
    "df_test['skills_cleaned'] = df_test['key_skills'].apply(clean_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_job_desig(desig):\n",
    "    job_desig = desig.lower()\n",
    "    job_desig = re.sub(r'[^a-z]', ' ', job_desig)\n",
    "    job_desig = re.sub(r'\\s+', ' ', job_desig)\n",
    "    return job_desig\n",
    "\n",
    "df_train['desig_cleaned'] = df_train['job_desig'].apply(clean_job_desig)\n",
    "df_test['desig_cleaned'] = df_test['job_desig'].apply(clean_job_desig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['job_description'].fillna('missing', inplace=True)\n",
    "test['job_description'].fillna('missing', inplace=True)\n",
    "\n",
    "def clean_job_desc(job):\n",
    "    job_desc = str(job).lower()\n",
    "    job_desc = re.sub(r'[^a-z]', ' ', job_desc)\n",
    "    job_desc = re.sub(r'\\s+', ' ', job_desc)\n",
    "    return job_desc\n",
    "\n",
    "df_train['job_desc_cleaned'] = df_train['job_description'].apply(clean_job_desc)\n",
    "df_test['job_desc_cleaned'] = df_test['job_description'].apply(clean_job_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_location(loc):\n",
    "    location = loc.lower()\n",
    "    location = re.sub(r'[^a-z]', ' ', location)\n",
    "    location = re.sub(r'\\s+', ' ', location)\n",
    "    return location\n",
    "\n",
    "df_train['loc_cleaned'] = df_train['location'].apply(clean_location)\n",
    "df_test['loc_cleaned'] = df_test['location'].apply(clean_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['job_type'].fillna('missingjobtype', inplace=True)\n",
    "train['job_type'].replace('Analytics', 'analytics', inplace=True)\n",
    "train['job_type'].replace('Analytic', 'analytics', inplace=True)\n",
    "train['job_type'].replace('ANALYTICS', 'analytics', inplace=True)\n",
    "train['job_type'].replace('analytic', 'analytics', inplace=True)\n",
    "\n",
    "test['job_type'].fillna('missingjobtype', inplace=True)\n",
    "test['job_type'].replace('Analytics', 'analytics', inplace=True)\n",
    "test['job_type'].replace('Analytic', 'analytics', inplace=True)\n",
    "test['job_type'].replace('ANALYTICS', 'analytics', inplace=True)\n",
    "test['job_type'].replace('analytic', 'analytics', inplace=True)\n",
    "\n",
    "df_train['job_type_cleaned'] = train['job_type'] \n",
    "df_test['job_type_cleaned'] = test['job_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_exp(exp):\n",
    "    val = re.sub(r'\\-',' ', exp)\n",
    "    val = val.split(' ')\n",
    "    val = int(val[0])\n",
    "    return val\n",
    "\n",
    "def max_exp(exp):\n",
    "    val = re.sub(r'\\-',' ', exp)\n",
    "    val = val.split(' ')\n",
    "    val = int(val[1])\n",
    "    return val\n",
    "\n",
    "df_train['min_exp'] = df_train['experience'].apply(min_exp)\n",
    "df_train['max_exp'] = df_train['experience'].apply(max_exp)\n",
    "\n",
    "df_test['min_exp'] = df_test['experience'].apply(min_exp)\n",
    "df_test['max_exp'] = df_test['experience'].apply(max_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_skills</th>\n",
       "      <th>job_desig</th>\n",
       "      <th>job_description</th>\n",
       "      <th>location</th>\n",
       "      <th>job_type</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "      <th>skills_cleaned</th>\n",
       "      <th>desig_cleaned</th>\n",
       "      <th>job_desc_cleaned</th>\n",
       "      <th>loc_cleaned</th>\n",
       "      <th>job_type_cleaned</th>\n",
       "      <th>min_exp</th>\n",
       "      <th>max_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team skills, communication skills, analytical ...</td>\n",
       "      <td>Senior Exploit and Vulnerability Researcher</td>\n",
       "      <td>Exp: Minimum 5 years;Good understanding of IOC...</td>\n",
       "      <td>Delhi NCR(Vikas Puri)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-7 yrs</td>\n",
       "      <td>6to10</td>\n",
       "      <td>team skills communication skills analytical sk...</td>\n",
       "      <td>senior exploit and vulnerability researcher</td>\n",
       "      <td>exp minimum years good understanding of ioc ru...</td>\n",
       "      <td>delhi ncr vikas puri</td>\n",
       "      <td>missingjobtype</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppc, logistics, inventory management, supply c...</td>\n",
       "      <td>Head SCM</td>\n",
       "      <td>He should have handled a team of atleast 5-6 d...</td>\n",
       "      <td>Sonepat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-17 yrs</td>\n",
       "      <td>10to15</td>\n",
       "      <td>ppc logistics inventory management supply chai...</td>\n",
       "      <td>head scm</td>\n",
       "      <td>he should have handled a team of atleast direc...</td>\n",
       "      <td>sonepat</td>\n",
       "      <td>missingjobtype</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          key_skills  \\\n",
       "0  team skills, communication skills, analytical ...   \n",
       "1  ppc, logistics, inventory management, supply c...   \n",
       "\n",
       "                                     job_desig  \\\n",
       "0  Senior Exploit and Vulnerability Researcher   \n",
       "1                                     Head SCM   \n",
       "\n",
       "                                     job_description               location  \\\n",
       "0  Exp: Minimum 5 years;Good understanding of IOC...  Delhi NCR(Vikas Puri)   \n",
       "1  He should have handled a team of atleast 5-6 d...                Sonepat   \n",
       "\n",
       "  job_type experience  salary  \\\n",
       "0      NaN    5-7 yrs   6to10   \n",
       "1      NaN  10-17 yrs  10to15   \n",
       "\n",
       "                                      skills_cleaned  \\\n",
       "0  team skills communication skills analytical sk...   \n",
       "1  ppc logistics inventory management supply chai...   \n",
       "\n",
       "                                 desig_cleaned  \\\n",
       "0  senior exploit and vulnerability researcher   \n",
       "1                                     head scm   \n",
       "\n",
       "                                    job_desc_cleaned            loc_cleaned  \\\n",
       "0  exp minimum years good understanding of ioc ru...  delhi ncr vikas puri    \n",
       "1  he should have handled a team of atleast direc...                sonepat   \n",
       "\n",
       "  job_type_cleaned  min_exp  max_exp  \n",
       "0   missingjobtype        5        7  \n",
       "1   missingjobtype       10       17  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['merged'] = (df_train['desig_cleaned'] + ' ' + df_train['job_desc_cleaned'] + ' ' + df_train['skills_cleaned']\n",
    "                      + ' ' + df_train['job_type_cleaned'])\n",
    "\n",
    "df_test['merged'] = (df_test['desig_cleaned'] + ' ' + df_test['job_desc_cleaned'] + ' ' + df_test['skills_cleaned']\n",
    "                     + ' ' + df_test['job_type_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_train['salary'] = le.fit_transform(df_train['salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(\n",
    "    df_train[['merged', 'loc_cleaned', 'min_exp', 'max_exp']], \n",
    "    df_train['salary'], test_size=0.20, \n",
    "    stratify=df_train['salary'], random_state=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sample texts X_train:  15840\n",
      "No. of sample texts X_cv   :  3961\n"
     ]
    }
   ],
   "source": [
    "print('No. of sample texts X_train: ', len(X_train))\n",
    "print('No. of sample texts X_cv   : ', len(X_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the model & predict on CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_merged = X_train['merged']\n",
    "X_train_loc = X_train['loc_cleaned']\n",
    "\n",
    "X_cv_merged = X_cv['merged']\n",
    "X_cv_loc = X_cv['loc_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = TfidfVectorizer(min_df=3, token_pattern=r'\\w{3,}', ngram_range=(1,3), max_df=0.9)\n",
    "tf2 = TfidfVectorizer(min_df=2, token_pattern=r'\\w{3,}')\n",
    "\n",
    "X_train_merged = tf1.fit_transform(X_train_merged)\n",
    "X_train_loc = tf2.fit_transform(X_train_loc)\n",
    "\n",
    "X_cv_merged = tf1.transform(X_cv_merged)\n",
    "X_cv_loc = tf2.transform(X_cv_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc1 = StandardScaler()\n",
    "X_train_MinExp = sc1.fit_transform(np.array(X_train['min_exp']).reshape(-1,1))\n",
    "X_cv_MinExp = sc1.transform(np.array(X_cv['min_exp']).reshape(-1,1))\n",
    "X_train_MinExp = sparse.csr_matrix(X_train_MinExp)\n",
    "X_cv_MinExp = sparse.csr_matrix(X_cv_MinExp)\n",
    "\n",
    "sc2 = StandardScaler()\n",
    "X_train_MaxExp = sc2.fit_transform(np.array(X_train['max_exp']).reshape(-1,1))\n",
    "X_cv_MaxExp = sc2.transform(np.array(X_cv['max_exp']).reshape(-1,1))\n",
    "X_train_MaxExp = sparse.csr_matrix(X_train_MaxExp)\n",
    "X_cv_MaxExp = sparse.csr_matrix(X_cv_MaxExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = hstack((X_train_merged, X_train_loc, X_train_MinExp, X_train_MaxExp))\n",
    "merged_cv  = hstack((X_cv_merged, X_cv_loc, X_cv_MinExp, X_cv_MaxExp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15840, 52320), (3961, 52320))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train.shape, merged_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(merged_train, label=y_train)\n",
    "test_data = lgb.Dataset(merged_cv, label=y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'objective': 'multiclass',\n",
    "         'num_iterations': 80,\n",
    "         'learning_rate': 0.04,  \n",
    "         'num_leaves': 23,\n",
    "         'max_depth': 7, \n",
    "         'min_data_in_leaf': 28, \n",
    "         'max_bin': 10, \n",
    "         'min_data_in_bin': 3,   \n",
    "         'num_class': 6,\n",
    "         'metric': 'multi_logloss'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.76691\n",
      "[2]\tvalid_0's multi_logloss: 1.74376\n",
      "[3]\tvalid_0's multi_logloss: 1.72196\n",
      "[4]\tvalid_0's multi_logloss: 1.70192\n",
      "[5]\tvalid_0's multi_logloss: 1.68307\n",
      "[6]\tvalid_0's multi_logloss: 1.66533\n",
      "[7]\tvalid_0's multi_logloss: 1.64857\n",
      "[8]\tvalid_0's multi_logloss: 1.63258\n",
      "[9]\tvalid_0's multi_logloss: 1.61737\n",
      "[10]\tvalid_0's multi_logloss: 1.60311\n",
      "[11]\tvalid_0's multi_logloss: 1.58971\n",
      "[12]\tvalid_0's multi_logloss: 1.57669\n",
      "[13]\tvalid_0's multi_logloss: 1.56444\n",
      "[14]\tvalid_0's multi_logloss: 1.55256\n",
      "[15]\tvalid_0's multi_logloss: 1.54125\n",
      "[16]\tvalid_0's multi_logloss: 1.53062\n",
      "[17]\tvalid_0's multi_logloss: 1.52027\n",
      "[18]\tvalid_0's multi_logloss: 1.51041\n",
      "[19]\tvalid_0's multi_logloss: 1.50066\n",
      "[20]\tvalid_0's multi_logloss: 1.49162\n",
      "[21]\tvalid_0's multi_logloss: 1.48305\n",
      "[22]\tvalid_0's multi_logloss: 1.47454\n",
      "[23]\tvalid_0's multi_logloss: 1.4665\n",
      "[24]\tvalid_0's multi_logloss: 1.45877\n",
      "[25]\tvalid_0's multi_logloss: 1.45139\n",
      "[26]\tvalid_0's multi_logloss: 1.44424\n",
      "[27]\tvalid_0's multi_logloss: 1.43724\n",
      "[28]\tvalid_0's multi_logloss: 1.43083\n",
      "[29]\tvalid_0's multi_logloss: 1.42436\n",
      "[30]\tvalid_0's multi_logloss: 1.41823\n",
      "[31]\tvalid_0's multi_logloss: 1.41251\n",
      "[32]\tvalid_0's multi_logloss: 1.4068\n",
      "[33]\tvalid_0's multi_logloss: 1.4013\n",
      "[34]\tvalid_0's multi_logloss: 1.39574\n",
      "[35]\tvalid_0's multi_logloss: 1.39068\n",
      "[36]\tvalid_0's multi_logloss: 1.38565\n",
      "[37]\tvalid_0's multi_logloss: 1.38075\n",
      "[38]\tvalid_0's multi_logloss: 1.37592\n",
      "[39]\tvalid_0's multi_logloss: 1.37142\n",
      "[40]\tvalid_0's multi_logloss: 1.36719\n",
      "[41]\tvalid_0's multi_logloss: 1.36304\n",
      "[42]\tvalid_0's multi_logloss: 1.35899\n",
      "[43]\tvalid_0's multi_logloss: 1.35508\n",
      "[44]\tvalid_0's multi_logloss: 1.35131\n",
      "[45]\tvalid_0's multi_logloss: 1.3475\n",
      "[46]\tvalid_0's multi_logloss: 1.34388\n",
      "[47]\tvalid_0's multi_logloss: 1.34042\n",
      "[48]\tvalid_0's multi_logloss: 1.33715\n",
      "[49]\tvalid_0's multi_logloss: 1.33398\n",
      "[50]\tvalid_0's multi_logloss: 1.33084\n",
      "[51]\tvalid_0's multi_logloss: 1.32782\n",
      "[52]\tvalid_0's multi_logloss: 1.32483\n",
      "[53]\tvalid_0's multi_logloss: 1.32205\n",
      "[54]\tvalid_0's multi_logloss: 1.31946\n",
      "[55]\tvalid_0's multi_logloss: 1.31691\n",
      "[56]\tvalid_0's multi_logloss: 1.31438\n",
      "[57]\tvalid_0's multi_logloss: 1.3118\n",
      "[58]\tvalid_0's multi_logloss: 1.30936\n",
      "[59]\tvalid_0's multi_logloss: 1.30678\n",
      "[60]\tvalid_0's multi_logloss: 1.30463\n",
      "[61]\tvalid_0's multi_logloss: 1.30244\n",
      "[62]\tvalid_0's multi_logloss: 1.30026\n",
      "[63]\tvalid_0's multi_logloss: 1.29812\n",
      "[64]\tvalid_0's multi_logloss: 1.29592\n",
      "[65]\tvalid_0's multi_logloss: 1.29383\n",
      "[66]\tvalid_0's multi_logloss: 1.29181\n",
      "[67]\tvalid_0's multi_logloss: 1.28998\n",
      "[68]\tvalid_0's multi_logloss: 1.28784\n",
      "[69]\tvalid_0's multi_logloss: 1.28601\n",
      "[70]\tvalid_0's multi_logloss: 1.28418\n",
      "[71]\tvalid_0's multi_logloss: 1.28249\n",
      "[72]\tvalid_0's multi_logloss: 1.28073\n",
      "[73]\tvalid_0's multi_logloss: 1.27912\n",
      "[74]\tvalid_0's multi_logloss: 1.27739\n",
      "[75]\tvalid_0's multi_logloss: 1.27571\n",
      "[76]\tvalid_0's multi_logloss: 1.27414\n",
      "[77]\tvalid_0's multi_logloss: 1.2728\n",
      "[78]\tvalid_0's multi_logloss: 1.27141\n",
      "[79]\tvalid_0's multi_logloss: 1.26986\n",
      "[80]\tvalid_0's multi_logloss: 1.26843\n"
     ]
    }
   ],
   "source": [
    "lgbm = lgb.train(params=param,\n",
    "                 train_set=train_data,\n",
    "                 num_boost_round=100,\n",
    "                 valid_sets=[test_data])\n",
    "\n",
    "y_pred_class = lgbm.predict(merged_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.4827063872759404\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for x in y_pred_class:\n",
    "    predictions.append(np.argmax(x))\n",
    "\n",
    "print('accuracy:', accuracy_score(y_cv, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_merged = df_train['merged']\n",
    "X_train_loc = df_train['loc_cleaned']\n",
    "\n",
    "X_test_merged = df_test['merged']\n",
    "X_test_loc = df_test['loc_cleaned']\n",
    "\n",
    "y_train = df_train['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = TfidfVectorizer(min_df=3, token_pattern=r'\\w{3,}', ngram_range=(1,3))\n",
    "tf2 = TfidfVectorizer(min_df=2, token_pattern=r'\\w{3,}')\n",
    "\n",
    "X_train_merged = tf1.fit_transform(X_train_merged)\n",
    "X_train_loc = tf2.fit_transform(X_train_loc)\n",
    "\n",
    "X_test_merged = tf1.transform(X_test_merged)\n",
    "X_test_loc = tf2.transform(X_test_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc1 = StandardScaler()\n",
    "X_train_MinExp = sc1.fit_transform(np.array(df_train['min_exp']).reshape(-1,1))\n",
    "X_test_MinExp = sc1.transform(np.array(df_test['min_exp']).reshape(-1,1))\n",
    "X_train_MinExp = sparse.csr_matrix(X_train_MinExp)\n",
    "X_test_MinExp = sparse.csr_matrix(X_test_MinExp)\n",
    "\n",
    "sc2 = StandardScaler()\n",
    "X_train_MaxExp = sc2.fit_transform(np.array(df_train['max_exp']).reshape(-1,1))\n",
    "X_test_MaxExp = sc2.transform(np.array(df_test['max_exp']).reshape(-1,1))\n",
    "X_train_MaxExp = sparse.csr_matrix(X_train_MaxExp)\n",
    "X_test_MaxExp = sparse.csr_matrix(X_test_MaxExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = hstack((X_train_merged, X_train_loc, X_train_MinExp, X_train_MaxExp))\n",
    "merged_test  = hstack((X_test_merged, X_test_loc, X_test_MinExp, X_test_MaxExp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(merged_train, label=y_train)\n",
    "\n",
    "param = {'objective': 'multiclass',\n",
    "         'num_iterations': 80,\n",
    "         'learning_rate': 0.04, \n",
    "         'num_leaves': 23,\n",
    "         'max_depth': 7, \n",
    "         'min_data_in_leaf': 28, \n",
    "         'max_bin': 10, \n",
    "         'min_data_in_bin': 3,   \n",
    "         'num_class': 6,\n",
    "         'metric': 'multi_logloss'\n",
    "         }\n",
    "\n",
    "lgbm = lgb.train(params=param, \n",
    "                 train_set=train_data)\n",
    "\n",
    "predictions = lgbm.predict(merged_test)\n",
    "\n",
    "y_pred_class = []\n",
    "for x in predictions:\n",
    "    y_pred_class.append(np.argmax(x))\n",
    "\n",
    "y_pred_class = le.inverse_transform(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(data=y_pred_class, columns=['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('output.xlsx', engine='xlsxwriter')\n",
    "df_sub.to_excel(writer,sheet_name='Sheet1', index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
